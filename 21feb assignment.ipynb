{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbce6385-21c1-498f-bb0c-c9a3561d343a",
   "metadata": {},
   "source": [
    "Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "Ans - Web scraping is an automatic method to obtain large amounts of data from websites. Most of this data is unstructured data in an HTML format which is then converted into structured data in a spreadsheet or a database so that it can be used in various applications. There are many different ways to perform web scraping to obtain data from websites. These include using online services, particular API’s or even creating your code for web scraping from scratch. Many large websites, like Google, Twitter, Facebook, StackOverflow, etc. have API’s that allow you to access their data in a structured format. This is the best option, but there are other sites that don’t allow users to access large amounts of data in a structured form or they are simply not that technologically advanced. In that situation, it’s best to use Web Scraping to scrape the website for data.\n",
    "Every where web scraping is using Monitoring e-commerce prices. Finding opportunities for investment. Analyzing social media web data. Applying machine learning techniques etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa69cfab-62d9-43f8-8287-08218af53a4b",
   "metadata": {},
   "source": [
    "Q2. What are the different methods used for Web Scraping?\n",
    "Ans - Web scraping refers to the process of extracting data from websites. There are several methods used for web scraping, including:\n",
    "\n",
    "Manual Scraping: This method involves manually copying and pasting data from websites into a spreadsheet or other data storage format.\n",
    "\n",
    "Parsing HTML: Web scrapers can use HTML parsers to extract data from the HTML code of a website. These parsers can extract specific elements, such as tables or lists, and convert them into a structured format.\n",
    "\n",
    "XPath: XPath is a query language used to navigate and extract data from XML and HTML documents. It allows web scrapers to select specific elements on a webpage and extract data from them.\n",
    "\n",
    "Regular Expressions: Regular expressions are a powerful tool for pattern matching and data extraction. They can be used to extract specific text from HTML code, such as email addresses or phone numbers.\n",
    "\n",
    "APIs: Many websites offer APIs (Application Programming Interfaces) that allow developers to access their data directly. This is often the easiest and most efficient way to extract data from a website, as the data is already structured and in a machine-readable format.\n",
    "\n",
    "Web Scraping Tools: There are many web scraping tools available that can automate the process of web scraping. These tools often use a combination of the above methods and can be customized to extract specific data from websites. Some popular web scraping tools include BeautifulSoup, Scrapy, and Selenium.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648c892c-834d-43ed-888a-3a99cd64a153",
   "metadata": {},
   "source": [
    "Q3. What is Beautiful Soup? Why is it used?\n",
    "Ans - Beautiful Soup is a Python library used for web scraping purposes. It is used to parse HTML and XML documents and extract data from them. Beautiful Soup provides a set of functions and methods that make it easy to navigate and search through the document tree.\n",
    "\n",
    "Beautiful Soup is used for web scraping because it simplifies the process of parsing HTML and XML documents. Without Beautiful Soup, parsing a web page would require writing a lot of code to navigate the document tree and extract data. With Beautiful Soup, the process is much simpler and more intuitive.\n",
    "\n",
    "Beautiful Soup can be used to extract data from a wide range of websites, from simple static websites to complex dynamic websites with JavaScript and other scripting languages. It can also handle poorly formatted HTML, which can be difficult to parse with other parsing libraries.\n",
    "\n",
    "Overall, Beautiful Soup is a powerful tool for web scraping that simplifies the process of parsing and extracting data from web pages, making it a popular choice for developers and data scientists working with web data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979c436f-03db-4bf8-bce8-001cc5a3ba24",
   "metadata": {},
   "source": [
    "Q4. Why is flask used in this Web Scraping project?\n",
    "Ans - Flask is a popular Python web framework that is used for building web applications. In a web scraping project, Flask can be used to create a simple web interface for the user to interact with the web scraper. Flask can also be used to host the web scraper on a web server, making it accessible to users over the internet.\n",
    "\n",
    "Using Flask in a web scraping project has several benefits:\n",
    "\n",
    "Easy to use: Flask is easy to learn and use, even for beginners. It has a simple and intuitive API that makes it easy to build web applications.\n",
    "\n",
    "Lightweight: Flask is a lightweight web framework that does not require a lot of resources. This makes it a good choice for small to medium-sized web scraping projects.\n",
    "\n",
    "Flexible: Flask is a flexible framework that can be customized to meet the specific needs of a web scraping project. It allows developers to add custom functionality to the web application as needed.\n",
    "\n",
    "Integration with other Python libraries: Flask integrates well with other Python libraries, including Beautiful Soup and Requests, which are commonly used in web scraping projects. This makes it easy to build a web scraper using these libraries and Flask."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9da1e7-da54-4bfe-8029-6871d620f9b3",
   "metadata": {},
   "source": [
    "Q5. Write the names of AWS services used in this project. Also, explain the use of each service.\n",
    "Ans - there are so meny services in aws but we use  two services in this project one is codepipline and 2nd is beanstak . \n",
    "beanstak that give resorces and codepipline give connectivity with github ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e651e20a-3623-4633-9bb2-e29b3203c62a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6779c161-b6d4-4b14-92e9-8d59c00725ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
